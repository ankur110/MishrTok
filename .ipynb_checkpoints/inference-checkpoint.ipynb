{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5d57ce4-2576-4592-a688-b4a36645e42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================================================================\n",
      "COMPREHENSIVE HINGLISH TOKENIZER BENCHMARK\n",
      "===============================================================================================\n",
      "\n",
      "Loading Local Model: models/hinglish_32k...\n",
      "Loaded tokenizer from models/hinglish_32k. (vocab size: 32,768)\n",
      "\n",
      "Starting comparison against industry standards...\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "CATEGORY           | Hinglish |  o200k  | cl100k  |  p50k   |  vs o200k \n",
      "------------------------------------------------------------------------\n",
      "Casual_Chat        |    20    |   23    |   24    |   28    |  ‚úÖ 1.15x  \n",
      "Casual_Chat        |    16    |   20    |   21    |   23    |  ‚úÖ 1.25x  \n",
      "Casual_Chat        |    25    |   25    |   28    |   28    |  ~ 1.00x  \n",
      "Casual_Chat        |    14    |   15    |   17    |   20    |  ‚úÖ 1.07x  \n",
      "Casual_Chat        |    18    |   20    |   22    |   24    |  ‚úÖ 1.11x  \n",
      "Tech_Discussion    |    19    |   21    |   23    |   25    |  ‚úÖ 1.11x  \n",
      "Tech_Discussion    |    18    |   18    |   20    |   24    |  ~ 1.00x  \n",
      "Tech_Discussion    |    19    |   16    |   18    |   21    |  üîª 0.84x  \n",
      "Tech_Discussion    |    16    |   17    |   19    |   23    |  ‚úÖ 1.06x  \n",
      "Tech_Discussion    |    18    |   19    |   19    |   22    |  ‚úÖ 1.06x  \n",
      "Emotional_Rant     |    26    |   30    |   33    |   36    |  ‚úÖ 1.15x  \n",
      "Emotional_Rant     |    22    |   31    |   35    |   37    |  ‚úÖ 1.41x  \n",
      "Emotional_Rant     |    24    |   25    |   30    |   32    |  ~ 1.04x  \n",
      "Emotional_Rant     |    19    |   24    |   27    |   30    |  ‚úÖ 1.26x  \n",
      "Emotional_Rant     |    16    |   19    |   24    |   24    |  ‚úÖ 1.19x  \n",
      "Code_Mixing_Heavy  |    20    |   20    |   22    |   24    |  ~ 1.00x  \n",
      "Code_Mixing_Heavy  |    23    |   24    |   26    |   27    |  ~ 1.04x  \n",
      "Code_Mixing_Heavy  |    14    |   16    |   18    |   20    |  ‚úÖ 1.14x  \n",
      "Code_Mixing_Heavy  |    16    |   15    |   17    |   17    |  üîª 0.94x  \n",
      "Code_Mixing_Heavy  |    17    |   19    |   20    |   22    |  ‚úÖ 1.12x  \n",
      "Hardcore_Hinglish  |    13    |   18    |   19    |   19    |  ‚úÖ 1.38x  \n",
      "Hardcore_Hinglish  |    17    |   23    |   25    |   26    |  ‚úÖ 1.35x  \n",
      "Hardcore_Hinglish  |    15    |   22    |   25    |   27    |  ‚úÖ 1.47x  \n",
      "Hardcore_Hinglish  |    10    |   13    |   15    |   15    |  ‚úÖ 1.30x  \n",
      "Hardcore_Hinglish  |    15    |   19    |   22    |   26    |  ‚úÖ 1.27x  \n",
      "Pure_Hindi         |    12    |   12    |   54    |   82    |  ~ 1.00x  \n",
      "Pure_Hindi         |    13    |   19    |   58    |   103   |  ‚úÖ 1.46x  \n",
      "Pure_Hindi         |    14    |   15    |   37    |   54    |  ‚úÖ 1.07x  \n",
      "Pure_Hindi         |    6     |    7    |   15    |   24    |  ‚úÖ 1.17x  \n",
      "Pure_Hindi         |    15    |   17    |   52    |   76    |  ‚úÖ 1.13x  \n",
      "\n",
      "============================================================\n",
      "TASK-WISE PERFORMANCE BREAKDOWN\n",
      "============================================================\n",
      "TASK CATEGORY        | Hinglish | GPT-4o  | IMPROVEMENT \n",
      "--------------------------------------------------------\n",
      "Casual_Chat          |   93    |   103   |   ‚úÖ 1.11x   \n",
      "Tech_Discussion      |   90    |   91    |   ‚úÖ 1.01x   \n",
      "Emotional_Rant       |   107   |   129   |   ‚úÖ 1.21x   \n",
      "Code_Mixing_Heavy    |   90    |   94    |   ‚úÖ 1.04x   \n",
      "Hardcore_Hinglish    |   70    |   95    |   ‚úÖ 1.36x   \n",
      "Pure_Hindi           |   60    |   70    |   ‚úÖ 1.17x   \n",
      "\n",
      "============================================================\n",
      "FINAL AGGREGATE STATS\n",
      "============================================================\n",
      "   Total Tokens (You):    510\n",
      "   Total Tokens (GPT-4o): 582\n",
      "   Global Efficiency:     1.141x\n",
      "\n",
      " VERDICT: HinglishBPE is 14.1% more efficient than GPT-4o.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tiktoken\n",
    "from statistics import mean\n",
    "from src.HinglishBPE import HinglishBPE \n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. CONFIGURATION\n",
    "# ---------------------------------------------------------\n",
    "YOUR_MODEL_PREFIX = \"models/hinglish_32k\"  \n",
    "\n",
    "COMPARISON_MODELS = [\"o200k_base\", \"cl100k_base\", \"p50k_base\"]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. EXPANDED DATASET (Now includes Pure Hindi)\n",
    "# ---------------------------------------------------------\n",
    "PROMPT_STYLES = {\n",
    "    \"Casual_Chat\": [\n",
    "        \"Are bhai tu tension na le, maine usko bol diya hai ki kal tak payment clear kar de.\",\n",
    "        \"Kya scene hai aaj raat ka? Netflix and chill ka bhi option hai waise.\",\n",
    "        \"Oye sun, wo jo kal notes bheje the na tune, wo incomplete hain. Unit 4 miss ho gaya.\",\n",
    "        \"Bhai tera birthday bash kab hai? Party toh banti hai boss!\",\n",
    "        \"Ghar pe sab kaise hain? Aunty ko meri taraf se namaste bolna.\"\n",
    "    ],\n",
    "    \"Tech_Discussion\": [\n",
    "        \"Model train kiya tha but validation loss kam nahi ho raha. Learning rate adjust karna padega.\",\n",
    "        \"React ka naya update dekha? Hooks ka usage simplify kar diya hai inhone.\",\n",
    "        \"Python virtual environment setup karte waqt error aa raha hai 'pip not found'.\",\n",
    "        \"Backend API response time bahut high hai, database indexing check karni padegi.\",\n",
    "        \"Deployment ke liye Docker container use kar rahe ho ya direct server pe push karoge?\"\n",
    "    ],\n",
    "    \"Emotional_Rant\": [\n",
    "        \"Zindagi mein peace hi nahi bacha hai yaar. Subah utho, office jao, boss ki chik-chik suno.\",\n",
    "        \"Mujhe samajh nahi aata log itna fake kyun hote hain. Munh pe kuch aur, peeth peeche kuch.\",\n",
    "        \"Sach bataun toh I am exhausted. Kabhi kabhi lagta hai sab chhod ke Himalayas chala jaun.\",\n",
    "        \"Dil tootne ka dard wahi samajh sakta hai jisne sacha pyaar kiya ho.\",\n",
    "        \"Itna effort daalne ke baad bhi appreciation nahi milta toh frustration hoti hai.\"\n",
    "    ],\n",
    "    \"Code_Mixing_Heavy\": [\n",
    "        \"Basically, problem ye hai ki jab hum API call karte hain, toh response time high hai.\",\n",
    "        \"Actually, mujhe laga tha ki event 5 baje start hoga. But apparently, schedule change ho gaya.\",\n",
    "        \"Obviously, agar tum hard work nahi karoge toh success kaise milegi?\",\n",
    "        \"Frankly speaking, ye idea practical nahi lag raha implementation ke perspective se.\",\n",
    "        \"Technically, ye bug nahi feature hai, but client ko kaise samjhayein?\"\n",
    "    ],\n",
    "    \"Hardcore_Hinglish\": [\n",
    "        \"Humne socha tha ki wo aayega, par wo aaya hi nahi.\",\n",
    "        \"Tum kahan jaa rahe ho? Ruko, main bhi chalta hoon tumhare saath.\",\n",
    "        \"Khana kha liya kya? Aaj maine biryani banayi hai, aa jao.\",\n",
    "        \"Ye raaz bhi uske saath hi chala gaya.\",\n",
    "        \"Zindagi ek safar hai suhana, yahan kal kya ho kisne jaana.\"\n",
    "    ],\n",
    "    \"Pure_Hindi\": [\n",
    "        \"‡§≠‡§æ‡§∞‡§§ ‡§è‡§ï ‡§µ‡§ø‡§∂‡§æ‡§≤ ‡§¶‡•á‡§∂ ‡§π‡•à ‡§î‡§∞ ‡§á‡§∏‡§ï‡•Ä ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø ‡§¨‡§π‡•Å‡§§ ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§π‡•à‡•§\",\n",
    "        \"‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§® ‡§î‡§∞ ‡§™‡•ç‡§∞‡•å‡§¶‡•ç‡§Ø‡•ã‡§ó‡§ø‡§ï‡•Ä ‡§ï‡•á ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞ ‡§Æ‡•á‡§Ç ‡§π‡§Æ‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§™‡•ç‡§∞‡§ó‡§§‡§ø ‡§ï‡•Ä ‡§π‡•à‡•§\",\n",
    "        \"‡§ï‡•É‡§™‡§Ø‡§æ ‡§Æ‡•Å‡§ù‡•á ‡§™‡§æ‡§®‡•Ä ‡§ï‡§æ ‡§è‡§ï ‡§ó‡§ø‡§≤‡§æ‡§∏ ‡§¶‡•Ä‡§ú‡§ø‡§Ø‡•á‡•§\",\n",
    "        \"‡§∏‡§§‡•ç‡§Ø‡§Æ‡•á‡§µ ‡§ú‡§Ø‡§§‡•á‡•§\",\n",
    "        \"‡§Ü‡§ú ‡§Æ‡•å‡§∏‡§Æ ‡§¨‡§π‡•Å‡§§ ‡§∏‡•Å‡§π‡§æ‡§µ‡§®‡§æ ‡§π‡•à, ‡§ö‡§≤‡•ã ‡§¨‡§æ‡§π‡§∞ ‡§ò‡•Ç‡§Æ‡§®‡•á ‡§ö‡§≤‡§§‡•á ‡§π‡•à‡§Ç‡•§\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def run_comprehensive_benchmark():\n",
    "    print(f\"\\n{'='*95}\")\n",
    "    print(f\"COMPREHENSIVE HINGLISH TOKENIZER BENCHMARK\")\n",
    "    print(f\"{'='*95}\\n\")\n",
    "\n",
    "    # 1. Load Your Model\n",
    "    print(f\"Loading Local Model: {YOUR_MODEL_PREFIX}...\")\n",
    "    my_tok = HinglishBPE()\n",
    "    try:\n",
    "        my_tok.load(YOUR_MODEL_PREFIX)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Load Comparison Models\n",
    "    others = {}\n",
    "    for model_name in COMPARISON_MODELS:\n",
    "        try:\n",
    "            others[model_name] = tiktoken.get_encoding(model_name)\n",
    "        except:\n",
    "            print(f\"Warning: Could not load {model_name}. Skipping.\")\n",
    "\n",
    "    print(\"\\nStarting comparison against industry standards...\\n\")\n",
    "\n",
    "    # 3. Print Detail Table Header\n",
    "    header = f\"{'CATEGORY':<18} | {'Hinglish':^8} | {'o200k':^7} | {'cl100k':^7} | {'p50k':^7} | {'vs o200k':^10}\"\n",
    "    print(\"-\" * len(header))\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    total_mine = 0\n",
    "    total_o200k = 0\n",
    "    \n",
    "    # Store category-wise statistics\n",
    "    category_stats = {} \n",
    "\n",
    "    # 4. Run Benchmark\n",
    "    for category, texts in PROMPT_STYLES.items():\n",
    "        cat_mine = 0\n",
    "        cat_o200k = 0\n",
    "        \n",
    "        for text in texts:\n",
    "            my_ids = my_tok.encode(text)\n",
    "            len_my = len(my_ids)\n",
    "            total_mine += len_my\n",
    "            cat_mine += len_my\n",
    "\n",
    "            counts = {}\n",
    "            for name, tokenizer in others.items():\n",
    "                counts[name] = len(tokenizer.encode(text))\n",
    "            \n",
    "            o200k_val = counts.get(\"o200k_base\", 0)\n",
    "            total_o200k += o200k_val\n",
    "            cat_o200k += o200k_val\n",
    "\n",
    "            # Calculating Efficiency vs GPT-4o (o200k)\n",
    "            ratio = o200k_val / len_my\n",
    "            \n",
    "            if ratio > 1.05:\n",
    "                imp_str = f\"‚úÖ {ratio:.2f}x\"\n",
    "            elif ratio < 0.95:\n",
    "                imp_str = f\"üîª {ratio:.2f}x\"\n",
    "            else:\n",
    "                imp_str = f\"~ {ratio:.2f}x\"\n",
    "\n",
    "            print(f\"{category:<18} | {len_my:^8} | {o200k_val:^7} | {counts.get('cl100k_base',0):^7} | {counts.get('p50k_base',0):^7} | {imp_str:^10}\")\n",
    "        \n",
    "        # Save aggregated stats for this category\n",
    "        category_stats[category] = (cat_mine, cat_o200k)\n",
    "\n",
    "    # 5. Category Breakdown Table\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"TASK-WISE PERFORMANCE BREAKDOWN\")\n",
    "    print(\"=\"*60)\n",
    "    cat_header = f\"{'TASK CATEGORY':<20} | {'Hinglish':^7} | {'GPT-4o':^7} | {'IMPROVEMENT':^12}\"\n",
    "    print(cat_header)\n",
    "    print(\"-\" * len(cat_header))\n",
    "    \n",
    "    for cat, (mine, other) in category_stats.items():\n",
    "        ratio = other / mine\n",
    "        if ratio > 1.0:\n",
    "            status = f\"‚úÖ {ratio:.2f}x\"\n",
    "        else:\n",
    "            status = f\"üîª {ratio:.2f}x\"\n",
    "        print(f\"{cat:<20} | {mine:^7} | {other:^7} | {status:^12}\")\n",
    "\n",
    "    # 6. Final Summary\n",
    "    avg_efficiency = total_o200k / total_mine\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"FINAL AGGREGATE STATS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"   Total Tokens (You):    {total_mine}\")\n",
    "    print(f\"   Total Tokens (GPT-4o): {total_o200k}\")\n",
    "    print(f\"   Global Efficiency:     {avg_efficiency:.3f}x\")\n",
    "\n",
    "    if avg_efficiency > 1.0:\n",
    "        print(f\"\\n VERDICT: HinglishBPE is {((avg_efficiency-1)*100):.1f}% more efficient than GPT-4o.\")\n",
    "    else:\n",
    "        print(f\"\\n VERDICT: HinglishBPE is slightly less efficient.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_comprehensive_benchmark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
